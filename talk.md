## ğŸ™ï¸ How to give this talk ğŸ™ï¸

## ğŸ› ï¸ Prerequisites ğŸ› ï¸

- ğŸ” Valid OVHcloud AI Endpoints token
- ğŸ“ set th token in a `.env` file create by copying the `.env.example` file
- â¬‡ï¸ be sure that all Python, JavaScript and Java dependencies are installed see [README](./README.md) for mote details.
  - activate the Python virtuel environment: `source .venv/bin/activate`

## ğŸ Python demos ğŸ

- ğŸ“‚ go to [python](./python) folder
- ğŸ› ï¸ source the environment: `source ../.env`

### ğŸ›‘ Blocking chatbot with no Framework ğŸ›‘

- â¬‡ï¸ In the [requirements.txt](./python/requirements.txt) file, declare the dependencies: `py-01-simple-requirements`
- ğŸ“ open the [blocking-chatbot-without-fwk](./python/blocking-chatbot-without-fwk.py)
- ğŸ“ use the snippets as written in the comments
- âš¡ï¸ run the script: `cd python` && `python blocking-chatbot-without-fwk.py`

### ğŸ›‘ Blocking chatbot with LangChain ğŸ›‘

- â¬‡ï¸ In the [requirements.txt](./python/requirements.txt) file, declare the dependencies: `py-07-langchain-blk-requirements`
- ğŸ“ open the [blocking-chatbot-langchain](./python/blocking-chatbot-langchain.py)
- ğŸ“ use the snippets as written in the comments
- âš¡ï¸ run the script: `cd python` && `python blocking-chatbot-langchain.py`

## ğŸ•¸ï¸ JavaScript demos ğŸ•¸ï¸

### ğŸ’¬ Streaming chatbot with LangChain ğŸ’¬

- â¬‡ï¸ In the [package.json](./javascript/package.json) file, declare the dependencies: `js-01-str-dependencies`
- ğŸ“ open the [chatbot-streaming](./javascript/chatbot-streaming.js)
- ğŸ“ use the snippets as written in the comments
- âš¡ï¸ run the script: `cd javascript` && `node chatbot-streaming.js`

## â˜•ï¸ Java demos â˜•ï¸

### ğŸ§  Memory chatbot with LangChain4j ğŸ§ 

- â¬‡ï¸ In the [pom.xml](./java/pom.xml) file, declare the dependencies: `java-01-mem-dependencies`
- ğŸ“ open the [MemoryStreamingChatbot](./java/src/main/java/com/ovhcloud/examples/aiendpoints/MemoryStreamingChatbot.java)
- ğŸ“ use the snippets as written in the comments
- âš¡ï¸ run the main class with VSCode debug view and `DEBUG CONSOLE` view
- ğŸ«£ comment the line 37
- âš¡ï¸ run the main class with VSCode debug view and `DEBUG CONSOLE` view

### ğŸ—ƒï¸ RAG with LangChain4j ğŸ—ƒï¸

- â¬‡ï¸ In the [pom.xml](./java/pom.xml) file, declare the dependencies: `java-07-rag-dependency`
- ğŸ“ open the [RAGStreamingChatbot](./java/src/main/java/com/ovhcloud/examples/aiendpoints/RAGStreamingChatbot.java)
- ğŸ“ use the snippets as written in the comments
- âš¡ï¸ run the main class with VSCode debug view and `DEBUG CONSOLE` view
- ğŸ«£ comment the line 76
- âš¡ï¸ run the main class with VSCode debug view and `DEBUG CONSOLE` view

### â¤ï¸ Sentiment analysis â¤ï¸

- â¬‡ï¸ In the [pom.xml](./java/pom.xml) file, declare the dependencies: `java-14-sentiment-dependency`
- ğŸ“ open the [SentimentsAnalysis](./java/src/main/java/fr/wilda/ai/nlp/SentimentsAnalysis.java)
- ğŸ“ use the snippets as written in the comments
- âš¡ï¸ run the main class with VSCode debug view and `DEBUG CONSOLE` view

## âš¡ï¸ Quarkus demos â˜•ï¸

### ğŸ¤– Virtual assistant ğŸ¤–

- âœ¨ create an empty project in the `tmp` folder: `quarkus create app fr.wilda.ai:ai-as-lib --extension='quarkus-langchain4j-mistral-ai,rest,quarkus-websockets-next' --no-wrapper`
- ğŸ“ open the [application.properties](./java-quarkus/src/main/resources/application.properties) file
- ğŸ“ use the snippets `quarkus-01-ai-langchain4j` 
- ğŸ“ open the [AIEndpointService](./java-quarkus/src/main/java/fr/wilda/ai/service/AIEndpointService.java) interface 
- ğŸ“ use the snippets as written in the comments
- ğŸ“ open the [Jarvis](./java-quarkus/src/main/java/fr/wilda/ai/Jarvis.java) interface
- ğŸ“ use the snippets as written in the comments
- ğŸ“ open the [application.properties](./java-quarkus/src/main/resources/application.properties) file
- ğŸ“ use the snippets `quarkus-07-ws-cors` 
- âš¡ï¸ run the web server: `cd react-client && npm start`

