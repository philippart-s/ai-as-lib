snippet java-mem-dependencies:
  name: "java-mem-dependencies"
  prefix: "java-01-mem-dependencies"
  scope: "xml"
  body: |
    <dependency>
      <groupId>dev.langchain4j</groupId>
      <artifactId>langchain4j</artifactId>
      <version>${langchain4j.version}</version>
    </dependency>

    <dependency>
      <groupId>dev.langchain4j</groupId>
      <artifactId>langchain4j-mistral-ai</artifactId>
      <version>${langchain4j.version}</version>
    </dependency>

snippet java-mem-interface:
  name: "java-mem-interface"
  prefix: "java-02-mem-interface"
  scope: "java"
  body: |
    interface Assistant {
      TokenStream chat(String message);
    }

snippet java-mem-model:
  name: "java-mem-model"
  prefix: "java-03-mem-model"
  scope: "java"
  body: |
    MistralAiStreamingChatModel streamingChatModel = MistralAiStreamingChatModel.builder()
            .apiKey(System.getenv("OVH_AI_ENDPOINTS_ACCESS_TOKEN"))
            .modelName(System.getenv("OVH_AI_ENDPOINTS_MODEL_NAME"))
            .baseUrl(
                    System.getenv("OVH_AI_ENDPOINTS_MODEL_URL"))
            .maxTokens(512)
            .build();

snippet java-mem-memory:
  name: "java-mem-memory"
  prefix: "java-04-mem-memory"
  scope: "java"
  body: |
    ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);

snippet java-mem-assistant:
  name: "java-mem-assistant"
  prefix: "java-05-mem-assistant"
  scope: "java"
  body: |
    Assistant assistant = AiServices.builder(Assistant.class)
        .streamingChatLanguageModel(streamingChatModel)
        .chatMemory(chatMemory)
    .build();

snippet java-mem-prompt:
  name: "java-mem-prompt"
  prefix: "java-06-mem-prompt"
  scope: "java"
  body: |
    _LOG.info("ðŸ’¬: My name is StÃ©phane.\n");
    TokenStream tokenStream = assistant.chat("My name is StÃ©phane.");
    _LOG.info("ðŸ¤–: ");
    tokenStream
        .onNext(_LOG::info)
        .onComplete(token -> {
          _LOG.info("\nðŸ’¬: Do you remember what is my name?\n");
          _LOG.info("ðŸ¤–: ");
          assistant.chat("Do you remember what is my name?")
              .onNext(_LOG::info)
              .onError(Throwable::printStackTrace).start();
        })
        .onError(Throwable::printStackTrace).start();

snippet java-rag-dependency:
  name: "java-rag-dependency"
  prefix: "java-07-rag-dependency"
  scope: "xml"
  body: |
    <dependency>
      <groupId>dev.langchain4j</groupId>
      <artifactId>langchain4j-ovh-ai</artifactId>
      <version>${langchain4j.version}</version>
    </dependency>

snippet java-rag-chunk:
  name: "java-rag-chunk"
  prefix: "java-08-rag-chunk"
  scope: "java"
  body: |
    // Load the document and split it into chunks
    DocumentParser documentParser = new TextDocumentParser();
    Document document = loadDocument(
      RAGStreamingChatbot.class.getResource("/rag-files/content.txt").getFile(),
      documentParser
    );
    DocumentSplitter splitter = DocumentSplitters.recursive(400, 0);

    List<TextSegment> segments = splitter.split(document);

snippet java-rag-embed:
  name: "java-rag-embed"
  prefix: "java-09-rag-embed"
  scope: "java"
  body: |
    // Do the embeddings and store them in an embedding store
    EmbeddingModel embeddingModel = OvhAiEmbeddingModel.builder()
            .apiKey(OVHCLOUD_API_KEY)
            .baseUrl(System.getenv("OVH_AI_ENDPOINTS_EMBEDDING_MODEL_URL"))
            .build();

snippet java-rag-store:
  name: "java-rag-store"
  prefix: "java-10-rag-store"
  scope: "java"
  body: |
    EmbeddingStore<TextSegment> embeddingStore = new InMemoryEmbeddingStore<>();
    embeddingStore.addAll(embeddings, segments);
    ContentRetriever contentRetriever = EmbeddingStoreContentRetriever.builder()
      .embeddingStore(embeddingStore)
      .embeddingModel(embeddingModel)
      .maxResults(5)
      .minScore(0.9)
    .build();

snippet java-rag-model:
  name: "java-rag-model"
  prefix: "java-11-rag-model"
  scope: "java"
  body: |
    MistralAiStreamingChatModel streamingChatModel = MistralAiStreamingChatModel.builder()
            .apiKey(OVHCLOUD_API_KEY)
            .modelName(System.getenv("OVH_AI_ENDPOINTS_MODEL_NAME"))
            .baseUrl(
                    System.getenv("OVH_AI_ENDPOINTS_MODEL_URL")
            )
            .maxTokens(512)
            .build();

snippet java-rag-assistant:
  name: "java-rag-assistant"
  prefix: "java-12-rag-assistant"
  scope: "java"
  body: |
    Assistant assistant = AiServices
      .builder(Assistant.class)
      .streamingChatLanguageModel(streamingChatModel)
      .contentRetriever(contentRetriever)
      .build();

snippet java-rag-prompt:
  name: "java-rag-prompt"
  prefix: "java-13-rag-prompt"
  scope: "java"
  body: |
    _LOG.info("\nðŸ’¬: What is AI Endpoints?\n");

    TokenStream tokenStream = assistant.chat("Can you explain me what is AI Endpoints?");
    _LOG.info("ðŸ¤–: ");
    tokenStream
        .onNext(_LOG::info)
        .onError(Throwable::printStackTrace)
        .start();

snippet java-sentiment-dependency:
  name: "java-sentiment-dependency"
  prefix: "java-14-sentiment-dependency"
  scope: "xml"
  body: |
    <dependency>
      <groupId>fr.wilda.ai</groupId>
      <artifactId>java-ai-toolkit</artifactId>
      <version>1.0.0</version>
    </dependency>

snippet java-sentiment-http:
  name: "java-sentiment-http"
  prefix: "java-15-sentiment-http"
  scope: "java"
  body: |
    // Create a HTTP client
    HttpClient client = HttpClient.newHttpClient();

snippet java-sentiment-request:
  name: "java-sentiment-request"
  prefix: "java-16-sentiment-request"
  scope: "java"
  body: |
    // Create a request builder
    HttpRequest request = HttpRequest.newBuilder()
            .uri(URI.create(System.getenv("OVH_AI_ENDPOINTS_SENTIMENT_MODEL_URL")))
            .POST(HttpRequest.BodyPublishers.ofString("I love Java"))
            .header("Content-Type", "application/json")
            .header("Authorization", "Bearer " + System.getenv("OVH_AI_ENDPOINTS_ACCESS_TOKEN"))
            .build();

snippet java-sentiment-response:
  name: "java-sentiment-response"
  prefix: "java-17-sentiment-response"
  scope: "java"
  body: |
    // Send the request and get the response
    HttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());

snippet java-sentiment-mapper:
  name: "java-sentiment-mapper"
  prefix: "java-18-sentiment-mapper"
  scope: "java"
  body: |
    // Deserialize the response to a Java object using Jackson
    ObjectMapper objectMapper = new ObjectMapper();
    Emotion responseObject = objectMapper.readValue(response.body(), Emotion.class);

snippet java-sentiment-display:
  name: "java-sentiment-display"
  prefix: "java-19-sentiment-display"
  scope: "java"
  body: |
    // Print the response status code and body
    _LOG.debug("Status code: " + response.statusCode());
    _LOG.debug("Response body: " + response.body());
    _LOG.info("Emotion: " + responseObject.toEmoji());

snippet quarkus-ai-langchain4j:
  name: "quarkus-ai-langchain4j"
  prefix: "quarkus-01-ai-langchain4j"
  body: |
    quarkus.langchain4j.mistralai.base-url=\${OVH_AI_ENDPOINTS_MODEL_URL}
    quarkus.langchain4j.mistralai.api-key=\${OVH_AI_ENDPOINTS_ACCESS_TOKEN}
    quarkus.langchain4j.mistralai.chat-model.max-tokens=512
    quarkus.langchain4j.mistralai.chat-model.model-name=\${OVH_AI_ENDPOINTS_MODEL_NAME}
    quarkus.langchain4j.mistralai.log-requests=false
    quarkus.langchain4j.mistralai.log-responses=true
    quarkus.langchain4j.mistralai.chat-model.temperature=0.2

snippet quarkus-ai-ai-service:
  name: "quarkus-ai-ai-service"
  prefix: "quarkus-02-ai-ai-service"
  scope: "java"
  body: |
    @SessionScoped
    @RegisterAiService(chatMemoryProviderSupplier = RegisterAiService.NoChatMemoryProviderSupplier.class)

snippet quarkus-ai-prompt:
  name: "quarkus-ai-prompt"
  prefix: "quarkus-03-ai-prompt"
  scope: "java"
  body: |
    @SystemMessage("You are a virtual assistant and your name is JARVIS.")
    @UserMessage("Answer as best possible to the following question: {question}. The answer must be in a style of a virtual assistant.")
    Multi<String> askAQuestion(String question);

snippet quarkus-websocket:
  name: "quarkus-websocket"
  prefix: "quarkus-04-websocket"
  scope: "java"
  body: |
    @WebSocket(path = "/jarvis")

snippet quarkus-ws-inject-service:
  name: "quarkus-ws-inject-service"
  prefix: "quarkus-05-ws-inject-service"
  scope: "java"
  body: |
    @Inject
    AIEndpointService aiEndpointService;

snippet quarkus-ws-onMessage:
  name: "quarkus-ws-onMessage"
  prefix: "quarkus-06-ws-onMessage"
  scope: "java"
  body: |
    return aiEndpointService.askAQuestion(message)
        .onItem()
        .call(i -> Uni.createFrom()
            .nullItem()
            .onItem()
            .delayIt()
            .by(Duration.ofMillis(200)));

snippet quarkus-ws-cors:
  name: "quarkus-ws-cors"
  prefix: "quarkus-07-ws-cors"
  body: |
    # Disable CORS
    quarkus.http.cors=true
    %dev.quarkus.http.cors.origins=/.*/